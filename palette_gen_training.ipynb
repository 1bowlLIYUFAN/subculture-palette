{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.sentence2vec import Sentence2Vec\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from skimage.color import lab2rgb, rgb2lab\n",
    "import pickle\n",
    "\n",
    "embed_model = Sentence2Vec()\n",
    "\n",
    "matplotlib.rcParams[u'font.sans-serif'] = ['simhei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CA_NET(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CA_NET, self).__init__()\n",
    "        self.t_dim = 150\n",
    "        self.c_dim = 150\n",
    "        self.fc = torch.nn.Linear(self.t_dim, self.c_dim * 2, bias=True)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def encode(self, text_embedding):\n",
    "#         x = self.relu(self.fc(text_embedding))\n",
    "        x = self.fc(text_embedding)\n",
    "        x = self.relu(x)\n",
    "        mu = x[:, :, :self.c_dim]\n",
    "        logvar = x[:, :, self.c_dim:]\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = torch.cuda.FloatTensor(std.size()).normal_(0.0, 1)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, text_embedding):\n",
    "        \n",
    "        mu, logvar = self.encode(text_embedding)\n",
    "        c_code = self.reparametrize(mu, logvar)\n",
    "        return c_code, mu, logvar\n",
    "\n",
    "    \n",
    "class EncoderRNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, n_layers, dropout_p):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "#         self.embed = Embed(input_size, 300, W_emb, True)\n",
    "#         self.embed = embed_model\n",
    "        # 768 is the size of embedding result\n",
    "        self.gru = torch.nn.GRU(768, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.ca_net = CA_NET()\n",
    "\n",
    "    def forward(self, word_inputs, hidden):\n",
    "#         embedded = embed_model.embed(word_inputs).transpose(0,1)\n",
    "        word_inputs = word_inputs.transpose(0, 1).to(device)\n",
    "        hidden = hidden.to(device)\n",
    "        output, hidden = self.gru(word_inputs, hidden)\n",
    "        c_code, mu, logvar = self.ca_net(output)\n",
    "\n",
    "        return c_code, hidden, mu, logvar\n",
    "\n",
    "    def init_hidden(self,batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "\n",
    "        return hidden\n",
    "\n",
    "\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, max_length=768):\n",
    "        super(Attn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.softmax = torch.nn.Softmax(dim=0)\n",
    "        self.attn_e = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.attn_h = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.attn_energy = torch.nn.Linear(self.hidden_size, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, each_size):\n",
    "        seq_len = encoder_outputs.size(0)\n",
    "        batch_size = encoder_outputs.size(1)\n",
    "        attn_energies = torch.zeros(seq_len,batch_size,1).cuda()\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            attn_energies[i] = self.score(hidden, encoder_outputs[i])\n",
    "\n",
    "        attn_energies = self.softmax(attn_energies) # (seq_len, batch_size, 1)\n",
    "        return attn_energies.permute(1,2,0)         # (batch_size, 1, seq_len)\n",
    "\n",
    "    def score(self, hidden, encoder_output):\n",
    "        encoder_ = self.attn_e(encoder_output)  # encoder output (batch_size, hidden_size)\n",
    "        hidden_ = self.attn_h(hidden)           # hidden (batch_size, hidden_size)\n",
    "        energy = self.attn_energy(self.sigmoid(encoder_ + hidden_))\n",
    "\n",
    "        return energy\n",
    "\n",
    "    \n",
    "class AttnDecoderRNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, n_layers=1, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.attn = Attn(hidden_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.palette_dim = 3\n",
    "\n",
    "        self.gru = torch.nn.GRUCell(self.hidden_size + self.palette_dim, hidden_size)\n",
    "\n",
    "        self.out = torch.nn.Sequential(\n",
    "                        torch.nn.Linear(hidden_size, hidden_size),\n",
    "                        torch.nn.ReLU(inplace=True),\n",
    "                        torch.nn.BatchNorm1d(hidden_size),\n",
    "                        torch.nn.Linear(hidden_size,self.palette_dim)\n",
    "                   )\n",
    "    def forward(self, last_palette, last_decoder_hidden, encoder_outputs, each_input_size, i):\n",
    "\n",
    "        # Compute context vector.\n",
    "        if i == 0:\n",
    "            context = torch.mean(encoder_outputs, dim=0, keepdim=True)\n",
    "            # Compute gru output.\n",
    "            gru_input = torch.cat((last_palette, context.squeeze(0)), 1)    \n",
    "            \n",
    "            gru_hidden = self.gru(gru_input, last_decoder_hidden)\n",
    "\n",
    "            # Generate palette color.\n",
    "            #palette = self.out(gru_hidden.squeeze(0))\n",
    "            palette = self.out(gru_hidden.squeeze(1))\n",
    "            return palette, context.unsqueeze(0), gru_hidden\n",
    "        else:\n",
    "            attn_weights = self.attn(last_decoder_hidden.squeeze(0), encoder_outputs, each_input_size)\n",
    "            context = torch.bmm(attn_weights, encoder_outputs.transpose(0,1))\n",
    "            \n",
    "            \n",
    "            # Compute gru output.\n",
    "            gru_input = torch.cat((last_palette, context.squeeze(1)), 1)\n",
    "            \n",
    "            gru_hidden = self.gru(gru_input, last_decoder_hidden)\n",
    "\n",
    "            # Generate palette color.\n",
    "            #palette = self.out(gru_hidden.squeeze(0))\n",
    "            palette = self.out(gru_hidden.squeeze(1))\n",
    "            return palette, context.unsqueeze(0), gru_hidden\n",
    "    \n",
    "    \n",
    "class DecoderRNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, n_layers=1, dropout_p=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.palette_dim = 3\n",
    "        \n",
    "        self.encoder = torch.nn.Linear()\n",
    "\n",
    "        self.gru = torch.nn.GRUCell(self.hidden_size + self.palette_dim, hidden_size)\n",
    "\n",
    "        self.out = torch.nn.Sequential(\n",
    "                        torch.nn.Linear(hidden_size, hidden_size),\n",
    "                        torch.nn.ReLU(inplace=True),\n",
    "                        torch.nn.BatchNorm1d(hidden_size),\n",
    "                        torch.nn.Linear(hidden_size,self.palette_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, last_palette, last_decoder_hidden, encoder_output):\n",
    "        context = encoder_output\n",
    "\n",
    "        # Compute gru output.\n",
    "        gru_input = torch.cat((last_palette, context.squeeze(1)), 1)\n",
    "        gru_hidden = self.gru(gru_input, last_decoder_hidden)\n",
    "\n",
    "        # Generate palette color.\n",
    "        # palette = self.out(gru_hidden.squeeze(0))\n",
    "        palette = self.out(gru_hidden.squeeze(1))\n",
    "        return palette, context.unsqueeze(0), gru_hidden\n",
    "\n",
    "\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, color_size=15, hidden_dim=150):\n",
    "        super(Discriminator, self).__init__()\n",
    "        curr_dim = color_size + hidden_dim\n",
    "\n",
    "        layers = []\n",
    "        layers.append(torch.nn.Linear(curr_dim, int(curr_dim/2)))\n",
    "        layers.append(torch.nn.ReLU(inplace=True))\n",
    "        layers.append(torch.nn.Linear(int(curr_dim/2), int(curr_dim/4)))\n",
    "        layers.append(torch.nn.ReLU(inplace=True))\n",
    "        layers.append(torch.nn.Linear(int(curr_dim/4), int(curr_dim/8)))\n",
    "        layers.append(torch.nn.ReLU(inplace=True))\n",
    "        layers.append(torch.nn.Linear(int(curr_dim/8), 1)) # 9 -> 1\n",
    "        layers.append(torch.nn.Sigmoid())\n",
    "\n",
    "        self.main = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, color, text):\n",
    "        out = torch.cat([color, text.squeeze(1)], dim=1) # color: batch x 15, text: batch x 768\n",
    "        out2 = self.main(out)\n",
    "        return out2.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text2ColorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text_path, palette_path):\n",
    "        self.text_path = text_path\n",
    "        self.palette_path = palette_path\n",
    "\n",
    "        self.text_data = pickle.load(open(text_path, 'rb'))\n",
    "        palette_data = pickle.load(open(palette_path, 'rb'))\n",
    "\n",
    "        palette_data = torch.FloatTensor(palette_data) / 255.\n",
    "\n",
    "        self.palette_list = []\n",
    "        for index, palettes in enumerate(palette_data):\n",
    "            temp = []\n",
    "            for palette in palettes:\n",
    "                rgb = np.array([palette[0], palette[1], palette[2]])\n",
    "                lab = rgb2lab(rgb[np.newaxis, np.newaxis, :], illuminant='D50').flatten()\n",
    "                temp.append(lab[0])\n",
    "                temp.append(lab[1])\n",
    "                temp.append(lab[2])\n",
    "            self.palette_list.append(temp)\n",
    "        \n",
    "        self.palette_list = torch.FloatTensor(self.palette_list)\n",
    "\n",
    "\n",
    "        self.embed_model = Sentence2Vec()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_item = self.embed_model.embed(' '.join(self.text_data[idx]))['pooler_output'].squeeze(1)\n",
    "        palette_item = self.palette_list[idx]\n",
    "\n",
    "        return text_item, palette_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "text_path = './data_for_training/palette_gen/words421.pkl'\n",
    "palette_path = './data/rgb421.pkl'\n",
    "\n",
    "batch_size = 16\n",
    "lr = 1e-4\n",
    "weight_decay = 5e-5\n",
    "beta1 = 0.5\n",
    "beta2 = 0.99\n",
    "hidden_dim = 768\n",
    "\n",
    "max_iter_cnt = 1e5\n",
    "\n",
    "print_every_iter = 1\n",
    "save_every_epoch = 3\n",
    "\n",
    "ckpt_dir = './palette_gen_ckpt/date_time'\n",
    "output_dir = './palette_gen_ckpt/output/date_time'\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "# utils\n",
    "def lab2rgb_1d(in_lab, clip=True):\n",
    "    tmp_rgb = lab2rgb(in_lab[np.newaxis, np.newaxis, :], illuminant='D50').flatten()\n",
    "    if clip:\n",
    "        tmp_rgb = np.clip(tmp_rgb, 0, 1)\n",
    "    return tmp_rgb\n",
    "\n",
    "\n",
    "# define data_loader\n",
    "dataset = Text2ColorDataset(text_path, palette_path)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/colorization/lib/python3.6/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "# define models\n",
    "encoder = EncoderRNN(hidden_size=150, n_layers=1, dropout_p=0.2).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size=150, n_layers=1, dropout_p=0.2).to(device)\n",
    "discriminator = Discriminator(color_size=15, hidden_dim=150).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "criterion_GAN = torch.nn.BCELoss()\n",
    "criterion_smoothL1 = torch.nn.SmoothL1Loss()\n",
    "\n",
    "def KL_loss(mu, logvar):\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.mean(KLD_element).mul_(-0.5)\n",
    "    return KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "G_parameters = list(encoder.parameters()) + list(decoder.parameters())\n",
    "\n",
    "g_optimizer = torch.optim.Adam(G_parameters, lr=lr, weight_decay=weight_decay)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training step\n",
    "def train_step(text, palettes):\n",
    "    batch_size = text.size(0)\n",
    "    nonzero_indices = list(torch.nonzero(text)[:, 0])\n",
    "    each_input_size = [nonzero_indices.count(j) for j in range(batch_size)]\n",
    "    \n",
    "    real_labels = torch.ones(batch_size).to(device)\n",
    "    fake_labels = torch.zeros(batch_size).to(device)\n",
    "\n",
    "    palette = torch.FloatTensor(batch_size, 3).zero_().to(device)\n",
    "    fake_palettes = torch.FloatTensor(batch_size, 15).zero_().to(device)\n",
    "\n",
    "    encoder_hidden = encoder.init_hidden(batch_size).to(device)\n",
    "    \n",
    "    encoder_outputs, decoder_hidden, mu, logvar = encoder(text, encoder_hidden)\n",
    "    \n",
    "    decoder_hidden = decoder_hidden.squeeze(0)\n",
    "\n",
    "    for i in range(5):\n",
    "        palette, decoder_context, decoder_hidden = decoder(palette,\n",
    "                                                           decoder_hidden,\n",
    "                                                           encoder_outputs, \n",
    "                                                           each_input_size, \n",
    "                                                           i)\n",
    "        fake_palettes[:, 3 * i:3 * (i+1)] = palette\n",
    "\n",
    "    \n",
    "    # Condition for the discriminator.\n",
    "    each_input_size = torch.FloatTensor(each_input_size).to(device)\n",
    "    each_input_size = each_input_size.unsqueeze(1).expand(batch_size, 150)\n",
    "    encoder_outputs = torch.sum(encoder_outputs, 0)\n",
    "    encoder_outputs = torch.div(encoder_outputs, each_input_size)\n",
    "    \n",
    "    # train discriminator\n",
    "    palettes = palettes.to(device)\n",
    "    \n",
    "    real = discriminator(palettes, encoder_outputs)\n",
    "    d_loss_real = criterion_GAN(real, real_labels)\n",
    "\n",
    "    fake = discriminator(fake_palettes, encoder_outputs)\n",
    "    d_loss_fake = criterion_GAN(fake, fake_labels)\n",
    "\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "    d_optimizer.zero_grad()\n",
    "    d_loss.backward(retain_graph=True)\n",
    "    d_optimizer.step()\n",
    "\n",
    "\n",
    "    # train generator\n",
    "    fake = discriminator(fake_palettes, encoder_outputs)\n",
    "    g_loss_GAN = criterion_GAN(fake, real_labels)\n",
    "\n",
    "    g_loss_smoothL1 = criterion_smoothL1(fake_palettes, palettes)\n",
    "\n",
    "    kl_loss = KL_loss(mu, logvar)\n",
    "\n",
    "    # g_loss = g_loss_GAN + g_loss_smoothL1 * self.args.lambda_sL1 + kl_loss * self.args.lambda_KL\n",
    "    g_loss = g_loss_GAN + g_loss_smoothL1 + kl_loss\n",
    "\n",
    "    # Backprop and optimize.\n",
    "    g_optimizer.zero_grad()\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    return g_loss, d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample some results in training process\n",
    "def sample(prefix, input_text='快乐 悲伤 浪漫'):\n",
    "    decoder.eval()\n",
    "    text = embed_model.embed(input_text)['pooler_output'].unsqueeze(0).to(device)\n",
    "    for x in range(2):  # saving 5 samples\n",
    "        fig1, axs1 = plt.subplots(nrows=1, ncols=5)\n",
    "        \n",
    "        batch_size = text.size(0)\n",
    "        nonzero_indices = list(torch.nonzero(text)[:, 0])\n",
    "        each_input_size = [nonzero_indices.count(j) for j in range(batch_size)]\n",
    "        \n",
    "        palette = torch.FloatTensor(batch_size, 3).zero_().to(device)\n",
    "        fake_palettes = torch.FloatTensor(batch_size, 15).zero_().to(device)\n",
    "        encoder_hidden = encoder.init_hidden(batch_size).to(device)\n",
    "\n",
    "        encoder_outputs, decoder_hidden, mu, logvar = encoder(text, encoder_hidden)\n",
    "        \n",
    "        decoder_hidden = decoder_hidden.squeeze(0)\n",
    "        \n",
    "        for i in range(5):\n",
    "            palette, decoder_context, decoder_hidden = decoder(palette,\n",
    "                                                               decoder_hidden,\n",
    "                                                               encoder_outputs,\n",
    "                                                               each_input_size,\n",
    "                                                               i)\n",
    "\n",
    "            fake_palettes[:, 3 * i:3 * (i + 1)] = palette\n",
    "        \n",
    "        axs1[0].set_title(input_text)\n",
    "#         print(fake_palettes.size())\n",
    "        fake_palettes = fake_palettes.squeeze(0)\n",
    "        for k in range(5):\n",
    "            lab = np.array([fake_palettes.data[3*k],\n",
    "                            fake_palettes.data[3*k+1],\n",
    "                            fake_palettes.data[3*k+2]], dtype='float64')\n",
    "            rgb = lab2rgb_1d(lab)\n",
    "            axs1[k].imshow([[rgb]])\n",
    "            axs1[k].axis('off')\n",
    "\n",
    "        fig1.savefig(os.path.join(output_dir,\n",
    "                                    'epoch{}_sample{}.jpg'.format(prefix, x+1)))\n",
    "        plt.close()\n",
    "    print('Saved train sample...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the whole train function\n",
    "def train():\n",
    "    print('Start training Loop...')\n",
    "\n",
    "    epoch = 0\n",
    "    iter_cnt = 0\n",
    "    iter_every_epoch = len(data_loader)\n",
    "\n",
    "    decoder.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    \n",
    "    while iter_cnt < max_iter_cnt:\n",
    "        for idx, batch in enumerate(data_loader):\n",
    "            text, palettes = batch\n",
    "            \n",
    "            g_loss, d_loss = train_step(text, palettes)\n",
    "            \n",
    "            exit(0)\n",
    "\n",
    "            iter_cnt += 1\n",
    "\n",
    "            if iter_cnt % print_every_iter == 0:\n",
    "                print('Epoch: {:.2f}, Iteration: {:6d}. G_Loss: {:.4f}, D_Loss: {:.4f}'.format(\n",
    "                        iter_cnt / iter_every_epoch, iter_cnt, g_loss, d_loss))\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "        if epoch % save_every_epoch == 0:\n",
    "            # save checkpoint \n",
    "            torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'discriminator_state_dict': discriminator.state_dict(),\n",
    "                    'g_opt_state_dict': g_optimizer.state_dict(),\n",
    "                    'd_opt_state_dict': d_optimizer.state_dict(),\n",
    "                    'loss': 0,\n",
    "                    }, os.path.join(ckpt_dir, 'ckpt_%d.pt' % epoch))\n",
    "\n",
    "            # sample\n",
    "            sample('%d_1' % epoch, '快乐 悲伤')\n",
    "            sample('%d_2' % epoch, '快乐 悲伤')\n",
    "            sample('%d_3' % epoch, '快乐 悲伤')\n",
    "            decoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    encoder.load_state_dict(torch.load('./ckpt/20121103/ckpt_666.pt', map_location=lambda storage, loc: storage)['encoder'])\n",
    "    decoder.load_state_dict(torch.load('./ckpt/20121103/ckpt_666.pt', map_location=lambda storage, loc: storage)['decoder_state_dict'])\n",
    "    decoder.eval()\n",
    "    \n",
    "    sample(1, '美好')\n",
    "    sample(2, '生命')\n",
    "    sample(3, '夜晚')\n",
    "    sample(4, '放肆')\n",
    "    sample(5, '童年')\n",
    "    sample(6, '秋天')\n",
    "    \n",
    "    sample(7, '美好 秋天')\n",
    "    sample(8, '生命 秋天')\n",
    "    sample(9, '夜晚 秋天')\n",
    "    sample(10, '放肆 秋天')\n",
    "    sample(11, '童年 秋天')\n",
    "    \n",
    "    \n",
    "    sample(12, '上班')\n",
    "    sample(13, '疼痛')\n",
    "    sample(14, '喊叫')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train sample...\n",
      "Saved train sample...\n",
      "Saved train sample...\n",
      "Saved train sample...\n",
      "Saved train sample...\n",
      "Saved train sample...\n",
      "Saved train sample...\n",
      "Saved train sample...\n",
      "Saved train sample...\n",
      "Saved train sample...\n",
      "Saved train sample...\n",
      "Saved train sample...\n",
      "Saved train sample...\n",
      "Saved train sample...\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}